{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surprising-mouth",
   "metadata": {},
   "source": [
    "### Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "limited-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warning messages\n",
    "# def warn(*args, **kwargs):\n",
    "#     pass\n",
    "# import warnings\n",
    "# warnings.warn = warn\n",
    "\n",
    "# Handle table-like data and matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Computations\n",
    "import itertools\n",
    "\n",
    "# saving models\n",
    "import joblib\n",
    "\n",
    "# Modelling Algorithms\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Modelling Helpers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-memphis",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-board",
   "metadata": {},
   "source": [
    "source: https://www.kaggle.com/c/fake-news/data\n",
    "\n",
    "train.csv: A full training dataset with the following attributes:\n",
    "\n",
    "+ id: unique id for a news article\n",
    "+ title: the title of a news article\n",
    "+ author: author of the news article\n",
    "+ text: the text of the article; could be incomplete\n",
    "+ label: a label that marks the article as potentially unreliable\n",
    "    - 1: unreliable\n",
    "    - 0: reliable\n",
    "\n",
    "test.csv: A testing training dataset with all the same attributes at train.csv without the label.\n",
    "submit.csv: A sample submission that you can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indoor-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv.zip') # This is the data we will be using to train/bulid our models\n",
    "test_data = pd.read_csv('data/test.csv.zip') # This is the data we will use to evalute our model at the end.\n",
    "test_labels = pd.read_csv('data/submit.csv') # This is the actual/correct label(y) we will be using to do our comparism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accomplished-yield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "noble-trick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>Daniel Victor</td>\n",
       "      <td>If at first you don’t succeed, try a different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n",
       "1  20801  Russian warships ready to strike terrorists ne...   \n",
       "2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
       "3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n",
       "4  20804                    Keiser Report: Meme Wars (E995)   \n",
       "\n",
       "                    author                                               text  \n",
       "0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...  \n",
       "1                      NaN  Russian warships ready to strike terrorists ne...  \n",
       "2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...  \n",
       "3            Daniel Victor  If at first you don’t succeed, try a different...  \n",
       "4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dimensional-reducing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  20800      0\n",
       "1  20801      1\n",
       "2  20802      0\n",
       "3  20803      1\n",
       "4  20804      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "knowing-banana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'author', 'text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "japanese-savage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'author', 'text'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "positive-finland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "powerful-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "compatible-counter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5200, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incorrect-literacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5200, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-syntax",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "clean-heater",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20242 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20761 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "corporate-given",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "every-archives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "title     122\n",
       "author    503\n",
       "text        7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-lottery",
   "metadata": {},
   "source": [
    "### Narrative: \n",
    "+ This shows that in the train_data, we have some missing values. we have 558 rows with missing news titles, 1957 rows with missing authors and 39 rows with missing news text/content\n",
    "\n",
    "+ In the test_data, we have 112 rows with missing news titles, 503 rows with missing authors and 7 rows with missing news text/content "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-biotechnology",
   "metadata": {},
   "source": [
    "Handling missing data\n",
    "    \n",
    "    This we will do by replacing/filling the missing datas with space ie. (' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bigger-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.fillna(' ', inplace=True,)\n",
    "test_data.fillna(' ', inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alive-necessity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "theoretical-ownership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "immune-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  train_data.label # class label/ target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "republican-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns = 'label') # Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-calculation",
   "metadata": {},
   "source": [
    "We will be creating a new feature \"news\" which will be the concatenation of the already existing features (ie. \"title\", \"author\" and \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "small-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating/combining title,author and main text to form a new feature called news\n",
    "X['news'] = X['author'] + ' '+ X['title']+ ' ' + X['text']\n",
    "test_data['news'] = test_data['author'] + ' '+ test_data['title'] + ' ' +test_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "metric-hepatitis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'author', 'text', 'news'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "silent-conjunction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus House Dem Aide: We Didn’t Even S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>Consortiumnews.com Why the Truth Might Get You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>Jessica Purkiss 15 Civilians Killed In Single ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>Howard Portnoy Iranian woman jailed for fictio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  Ever get the feeling your life circles the rou...   \n",
       "2  Why the Truth Might Get You Fired October 29, ...   \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...   \n",
       "4  Print \\nAn Iranian woman has been sentenced to...   \n",
       "\n",
       "                                                news  \n",
       "0  Darrell Lucus House Dem Aide: We Didn’t Even S...  \n",
       "1  Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...  \n",
       "2  Consortiumnews.com Why the Truth Might Get You...  \n",
       "3  Jessica Purkiss 15 Civilians Killed In Single ...  \n",
       "4  Howard Portnoy Iranian woman jailed for fictio...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "unsigned-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the data into train and test data we only using the news feature which is a combination of the other features.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['news'],\n",
    "                                                    y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-freight",
   "metadata": {},
   "source": [
    "## Machine Learning Models with Count Vectorizer and TF-IDF Vectorizer\n",
    "\n",
    "+ The vectorization is to convect the text data to vectors after which our different machine learning models can be applied.\n",
    "\n",
    "+ For the vectorizing, we will be using two vectorizing algorithms. we will build our models with both after which we compare their accuracy score to see which performed better. and the one with the best perrfomance will be our final model. \n",
    "\n",
    "+ The two vectorizing algorithm we will be using are:\n",
    "    - Count Vectorizer also known as Bag of Words, and\n",
    "    - Term Frequency–Inverse Document Frequency also known as TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-bahamas",
   "metadata": {},
   "source": [
    "#### Using Naive Bayes ML model with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "correct-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english') \n",
    "# Fit and transform the training data.\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "positive-wallace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.15)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using MultinomialNB with the count vectorized data\n",
    "nb_classifier = MultinomialNB(alpha = 0.15)\n",
    "nb_classifier.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "tribal-money",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9415865384615385\n"
     ]
    }
   ],
   "source": [
    "# checking the accurracy with the model\n",
    "pred_count = nb_classifier.predict(count_test)\n",
    "acc_count = metrics.accuracy_score(y_test, pred_count)\n",
    "print(acc_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-battlefield",
   "metadata": {},
   "source": [
    "#### Using Naive Bayes ML model with TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "checked-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "#Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "#Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bulgarian-preliminary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using MultinomialNB with the count vectorized data\n",
    "nb_classifier = MultinomialNB(alpha = 0.01)\n",
    "nb_classifier.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "passive-victoria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9432692307692307\n"
     ]
    }
   ],
   "source": [
    "pred_tfidf = nb_classifier.predict(tfidf_test)\n",
    "acc_tfidf = metrics.accuracy_score(y_test, pred_tfidf)\n",
    "print(acc_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-circus",
   "metadata": {},
   "source": [
    "#### Narative:\n",
    "+ from the above, using tf-idf vectorizer performed slightly better than count vectorizer\n",
    "+ hence we will be using it for our final build\n",
    "+ For the final build, we will be using the Pipeline function from sklearn to pass both the vectorizer and build our model all in one line\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "under-andrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('TF-IDF vectorizer',\n",
       "                 TfidfVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('MultinomialNB', MultinomialNB(alpha=0.15))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_with_countvectorizer = Pipeline([('TF-IDF vectorizer', TfidfVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "                 ('MultinomialNB', MultinomialNB(alpha=0.15))])\n",
    "# Fit the training data to the model\n",
    "NB_with_countvectorizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "secondary-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our models\n",
    "with open('models/fake_news_nb_model', 'wb') as f:\n",
    "    joblib.dump(NB_with_countvectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-tooth",
   "metadata": {},
   "source": [
    "### Conclusson:\n",
    "+ using the data we got from kaggle which contains both fake and real news, we have successfully built a model of 94.43% accuracy and this is done using multinomial Naive Bayes Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-anger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
